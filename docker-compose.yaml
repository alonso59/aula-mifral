services:
  open-webui:
    build: .                      # builds your local Open WebUI repo
    image: open-webui-local:latest
    container_name: open-webui
    ports:
      - "3000:8080"
    volumes:
      - openwebui_data:/app/backend/data
    env_file:
      - .env                      # keep your other vars
    depends_on:
      - llm-runner
    restart: unless-stopped

  llm-runner:
    provider:
      type: model
      options:
        model: ai/smollm2:360M-Q4_K_M

  # cloudflared:
  #   image: cloudflare/cloudflared:latest
  #   command: tunnel --no-autoupdate run
  #   environment:
  #     - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}
  #   depends_on:
  #     - open-webui
  #   restart: unless-stopped

volumes:
  openwebui_data: {}